{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tCNHT9BxJWYN",
        "outputId": "2afe33f0-a3a3-4660-ca20-bacf32c0cffe"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "13/13 [==============================] - 0s 2ms/step\n",
            "Best Parameters: {'batch_size': 64, 'epochs': 150}\n",
            "10/10 [==============================] - 0s 2ms/step\n",
            "Best Model: Time Frame Prediction Loss: 5.800027784332864, MAE: 1.2701262069397232, RMSE: 2.4083246841596884, R-squared: 0.852264473580445\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score\n",
        "import numpy as np\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Dropout\n",
        "from keras.optimizers import Adam\n",
        "from sklearn.base import BaseEstimator, RegressorMixin\n",
        "\n",
        "# Read the dataset\n",
        "data_subset = pd.read_csv('/content/IBM-HR-Employee-Attrition.csv')\n",
        "\n",
        "# Map the 'Attrition' column to numeric labels\n",
        "data_subset['Attrition'] = data_subset['Attrition'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Selecting features for time frame prediction\n",
        "X_timeframe = data_subset[['Age', 'DistanceFromHome', 'Education','DailyRate','HourlyRate', 'JobInvolvement',\n",
        "                           'JobSatisfaction', 'MonthlyIncome', 'PercentSalaryHike','WorkLifeBalance',\n",
        "                           'YearsSinceLastPromotion', 'PerformanceRating', 'Attrition','YearsInCurrentRole','YearsWithCurrManager',\n",
        "                           'EnvironmentSatisfaction', 'NumCompaniesWorked','TotalWorkingYears']]\n",
        "\n",
        "# Target variable for time frame prediction\n",
        "y_timeframe = data_subset['YearsAtCompany']\n",
        "\n",
        "# Split data into training and testing sets for time frame prediction\n",
        "X_train_timeframe, X_test_timeframe, y_train_timeframe, y_test_timeframe = train_test_split(X_timeframe, y_timeframe, test_size=0.2, random_state=42)\n",
        "\n",
        "# Data scaling for time frame prediction\n",
        "scaler_timeframe = StandardScaler()\n",
        "X_train_timeframe_scaled = scaler_timeframe.fit_transform(X_train_timeframe)\n",
        "X_test_timeframe_scaled = scaler_timeframe.transform(X_test_timeframe)\n",
        "\n",
        "# Define the neural network model for time frame prediction\n",
        "def create_model(batch_size=32, epochs=100):\n",
        "    model = Sequential([\n",
        "        Dense(128, activation='relu', input_shape=(X_train_timeframe_scaled.shape[1],)),\n",
        "        Dropout(0.2),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.2),\n",
        "        Dense(1, activation='linear')\n",
        "    ])\n",
        "    optimizer = Adam(learning_rate=0.001)\n",
        "    model.compile(optimizer=optimizer, loss='mean_squared_error', metrics=['mae', 'mse', 'accuracy'])\n",
        "    return model\n",
        "\n",
        "# Train multiple models\n",
        "num_models = 5\n",
        "models = []\n",
        "for i in range(num_models):\n",
        "    model = create_model()\n",
        "    model.compile(optimizer='adam', loss='mean_squared_error', metrics=['mae', 'mse', 'accuracy'])\n",
        "    history = model.fit(X_train_timeframe_scaled, y_train_timeframe, epochs=150, batch_size=64, verbose=0, validation_split=0.2)\n",
        "    models.append(model)\n",
        "\n",
        "# Define KerasRegressor wrapper class\n",
        "class KerasRegressorWrapper(BaseEstimator, RegressorMixin):\n",
        "    def __init__(self, build_fn, batch_size=32, epochs=100, **kwargs):\n",
        "        self.build_fn = build_fn\n",
        "        self.batch_size = batch_size\n",
        "        self.epochs = epochs\n",
        "        self.kwargs = kwargs\n",
        "        self.model = None\n",
        "\n",
        "    def fit(self, X, y):\n",
        "        self.model = self.build_fn(batch_size=self.batch_size, epochs=self.epochs, **self.kwargs)\n",
        "        self.model.fit(X, y, epochs=self.epochs, batch_size=self.batch_size, verbose=0)\n",
        "        return self\n",
        "\n",
        "    def predict(self, X):\n",
        "        return self.model.predict(X)\n",
        "\n",
        "# Create the KerasRegressor wrapper\n",
        "keras_regressor = KerasRegressorWrapper(build_fn=create_model)\n",
        "\n",
        "# Define the grid search parameters\n",
        "param_grid = {\n",
        "    'batch_size': [32, 64],\n",
        "    'epochs': [100, 150],\n",
        "}\n",
        "\n",
        "# Create the grid search object\n",
        "grid_search = GridSearchCV(estimator=keras_regressor, param_grid=param_grid, scoring='neg_mean_squared_error', cv=3)\n",
        "\n",
        "# Perform grid search\n",
        "grid_result = grid_search.fit(X_train_timeframe_scaled, y_train_timeframe)\n",
        "\n",
        "# Print the best parameters found\n",
        "print(\"Best Parameters:\", grid_result.best_params_)\n",
        "\n",
        "# Evaluate the best model\n",
        "best_model = grid_result.best_estimator_\n",
        "predictions = best_model.predict(X_test_timeframe_scaled)\n",
        "\n",
        "# Calculate evaluation metrics\n",
        "ensemble_loss = mean_squared_error(y_test_timeframe, predictions)\n",
        "ensemble_mae = mean_absolute_error(y_test_timeframe, predictions)\n",
        "ensemble_rmse = np.sqrt(mean_squared_error(y_test_timeframe, predictions))\n",
        "ensemble_r2 = r2_score(y_test_timeframe, predictions)\n",
        "\n",
        "print(f'Best Model: Time Frame Prediction Loss: {ensemble_loss}, MAE: {ensemble_mae}, RMSE: {ensemble_rmse}, R-squared: {ensemble_r2}')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Time Frame Prediction Loss: The average loss or error in predicting time frames is approximately 5.8 out of 100\n",
        "\n",
        "Mean Absolute Error (MAE): The average absolute error between predicted and actual time frames is approximately 1.27. MAE represents the average magnitude of errors in the predictions.\n",
        "\n",
        "Root Mean Squared Error (RMSE): The square root of the average squared differences between predicted and actual time frames is approximately 2.40\n",
        "\n",
        "R-squared (RÂ²): The model explains approximately 85% of the variability in the time frames\n",
        "\n",
        "Overall, the ensemble model shows reasonable performance in predicting time frames, with low prediction loss, MAE, and RMSE, and a moderate to high R-squared value."
      ],
      "metadata": {
        "id": "nNgMc1vETQBC"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Print the best parameters found\n",
        "print(\"Best Parameters:\", grid_result.best_params_)\n",
        "\n",
        "# Get the best model\n",
        "best_model = grid_result.best_estimator_\n",
        "\n",
        "# Save the best model along with its parameters\n",
        "best_model_params = {\n",
        "    'best_batch_size': best_model.batch_size,\n",
        "    'best_epochs': best_model.epochs\n",
        "}\n",
        "\n",
        "best_model.model.save('best_timeframe_model_final1.keras')\n",
        "\n",
        "# Print the best model parameters\n",
        "print(\"Best Model Parameters:\", best_model_params)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gcbeLcLRKJ-7",
        "outputId": "a472f922-9556-49e9-aedd-17ebff29d6a2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'batch_size': 64, 'epochs': 150}\n",
            "Best Model Parameters: {'best_batch_size': 64, 'best_epochs': 150}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "8vLwAyY4VCzb"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}