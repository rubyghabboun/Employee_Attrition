{
<<<<<<< HEAD
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HiWZOEcMu6TU",
    "outputId": "58debc7f-38ec-4840-f6f2-fedfc303524d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.88      0.97      0.93       255\n",
      "           1       0.46      0.15      0.23        39\n",
      "\n",
      "    accuracy                           0.86       294\n",
      "   macro avg       0.67      0.56      0.58       294\n",
      "weighted avg       0.83      0.86      0.83       294\n",
      "\n",
      "Best parameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': False}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Read the dataset\n",
    "data = pd.read_csv('/content/IBM-HR-Employee-Attrition.csv')\n",
    "\n",
    "# Map the 'Attrition' column to numeric labels\n",
    "data['Attrition'] = data['Attrition'].map({'Yes': 1, 'No': 0})\n",
    "\n",
    "# Selecting features for attrition prediction\n",
    "X = data[['Age', 'DistanceFromHome', 'Education',\n",
    "          'JobSatisfaction', 'MonthlyIncome', 'PercentSalaryHike',\n",
    "          'TotalWorkingYears', 'YearsAtCompany', 'YearsSinceLastPromotion',\n",
    "          'PerformanceRating']]\n",
    "\n",
    "# Target variable for attrition prediction\n",
    "y = data['Attrition']\n",
    "\n",
    "# Splitting data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Balancing the class distribution using RandomOverSampler\n",
    "oversampler = RandomOverSampler(random_state=42)\n",
    "X_train_over, y_train_over = oversampler.fit_resample(X_train, y_train)\n",
    "\n",
    "# Data scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train_over)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Define the parameter grid for randomized search\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'max_depth': [5, 10, 15, None],\n",
    "    'min_samples_split': [2, 5, 10],\n",
    "    'min_samples_leaf': [1, 2, 4],\n",
    "    'bootstrap': [True, False]\n",
    "}\n",
    "\n",
    "# Define the random forest classifier\n",
    "rf = RandomForestClassifier(random_state=42)\n",
    "\n",
    "# Perform randomized search for hyperparameter optimization\n",
    "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=50, cv=5, scoring='accuracy', random_state=42)\n",
    "random_search.fit(X_train_scaled, y_train_over)\n",
    "\n",
    "# Get the best model from the randomized search\n",
    "best_model = random_search.best_estimator_\n",
    "\n",
    "# Make predictions on the test set\n",
    "y_pred = best_model.predict(X_test_scaled)\n",
    "\n",
    "# Evaluate the model\n",
    "print(classification_report(y_test, y_pred))\n",
    "print(f'Best parameters: {random_search.best_params_}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
=======
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HiWZOEcMu6TU",
        "outputId": "58debc7f-38ec-4840-f6f2-fedfc303524d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.97      0.93       255\n",
            "           1       0.46      0.15      0.23        39\n",
            "\n",
            "    accuracy                           0.86       294\n",
            "   macro avg       0.67      0.56      0.58       294\n",
            "weighted avg       0.83      0.86      0.83       294\n",
            "\n",
            "Best parameters: {'n_estimators': 200, 'min_samples_split': 2, 'min_samples_leaf': 1, 'max_depth': None, 'bootstrap': False}\n"
          ]
        }
      ],
      "source": [
        "from sklearn.model_selection import train_test_split, RandomizedSearchCV\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from imblearn.over_sampling import RandomOverSampler\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "\n",
        "# Read the dataset\n",
        "data = pd.read_csv('/content/IBM-HR-Employee-Attrition.csv')\n",
        "\n",
        "# Map the 'Attrition' column to numeric labels\n",
        "data['Attrition'] = data['Attrition'].map({'Yes': 1, 'No': 0})\n",
        "\n",
        "# Selecting features for attrition prediction\n",
        "X = data[['Age', 'DistanceFromHome', 'Education',\n",
        "          'JobSatisfaction', 'MonthlyIncome', 'PercentSalaryHike',\n",
        "          'TotalWorkingYears', 'YearsAtCompany', 'YearsSinceLastPromotion',\n",
        "          'PerformanceRating']]\n",
        "\n",
        "# Target variable for attrition prediction\n",
        "y = data['Attrition']\n",
        "\n",
        "# Splitting data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Balancing the class distribution using RandomOverSampler\n",
        "oversampler = RandomOverSampler(random_state=42)\n",
        "X_train_over, y_train_over = oversampler.fit_resample(X_train, y_train)\n",
        "\n",
        "# Data scaling\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train_over)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Define the parameter grid for randomized search\n",
        "param_grid = {\n",
        "    'n_estimators': [100, 200, 300],\n",
        "    'max_depth': [5, 10, 15, None],\n",
        "    'min_samples_split': [2, 5, 10],\n",
        "    'min_samples_leaf': [1, 2, 4],\n",
        "    'bootstrap': [True, False]\n",
        "}\n",
        "\n",
        "# Define the random forest classifier\n",
        "rf = RandomForestClassifier(random_state=42)\n",
        "\n",
        "# Perform randomized search for hyperparameter optimization\n",
        "random_search = RandomizedSearchCV(estimator=rf, param_distributions=param_grid, n_iter=50, cv=5, scoring='accuracy', random_state=42)\n",
        "random_search.fit(X_train_scaled, y_train_over)\n",
        "\n",
        "# Get the best model from the randomized search\n",
        "best_model = random_search.best_estimator_\n",
        "\n",
        "# Make predictions on the test set\n",
        "y_pred = best_model.predict(X_test_scaled)\n",
        "\n",
        "# Evaluate the model\n",
        "print(classification_report(y_test, y_pred))\n",
        "print(f'Best parameters: {random_search.best_params_}')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since the dataset is imbalanced with 82% of instances belonging to class 0 (no attrition), it's important to consider the class distribution when interpreting the model's performance. In such cases, the model may achieve high accuracy by simply predicting the majority class, but it may perform poorly in predicting the minority class (attrition).\n",
        "So focusing on class 0 and leveraging additional models, such as the time frame prediction model, can provide deeper insights into employee departure behavior and contribute to more effective decision-making.\n",
        "\n",
        "Precision: For class 0 (no attrition), the precision is 0.88, indicating that 88% of the instances were predicted right.\n",
        "\n",
        "Recall: For class 0, the recall is 0.97, suggesting that 97% of the actual no attrition cases are correctly identified\n",
        "\n",
        "Accuracy: The overall accuracy of the model is 86%, indicating the proportion of correctly predicted instances out of all instances. "
      ]
>>>>>>> eac5860d877afa5b7b6a15efbd112610dbd49037
    },
    "id": "KVvqr0s0xLGI",
    "outputId": "11779c6c-374b-46af-89ce-64c3878244b5"
   },
   "outputs": [
    {
<<<<<<< HEAD
     "data": {
      "text/plain": [
       "['best_random_forest_model_ATTRITION.pkl']"
=======
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVvqr0s0xLGI",
        "outputId": "11779c6c-374b-46af-89ce-64c3878244b5"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['best_random_forest_model_ATTRITION.pkl']"
            ]
          },
          "execution_count": 9,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import joblib\n",
        "\n",
        "# Save the best model\n",
        "joblib.dump(best_model, 'best_random_forest_model_ATTRITION.pkl')"
>>>>>>> eac5860d877afa5b7b6a15efbd112610dbd49037
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
<<<<<<< HEAD
   ],
   "source": [
    "import joblib\n",
    "\n",
    "# Save the best model\n",
    "joblib.dump(best_model, 'best_random_forest_model_ATTRITION.pkl')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
=======
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
>>>>>>> eac5860d877afa5b7b6a15efbd112610dbd49037
}
